{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMH9fX0UiIyIaJklzDx0Zva"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dEGsuxetQ8ez"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìå **Problem:** Struggling with Disorganized, Unproductive Meetings?\n",
        "We've all sat through meetings that drag on, lack focus, and end without clear outcomes. It's easy to lose track of key points, action items, or even who said what. And once the meeting ends? You're left sorting through messy notes ‚Äî or worse, wondering, ‚ÄúWhat did we actually decide?‚Äù"
      ],
      "metadata": {
        "id": "03mjdCMxWL7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Solution: Meet Your AI-Powered Meeting Assistant ‚Äî MinuteMaker\n",
        "MinuteMaker transforms your messy, hour-long meeting into:**\n",
        "\n",
        "üìã A clean, concise summary\n",
        "\n",
        "üí¨ A smart Q&A chatbot trained on your conversation\n",
        "\n",
        "üìä A ready-to-use PowerPoint slide deck\n",
        "\n",
        "Built with cutting-edge tools like OpenAI Whisper, Google Gemini, ChromaDB, and Python automation, MinuteMaker turns conversation into actionable insights ‚Äî instantly"
      ],
      "metadata": {
        "id": "b_mWRZnQWR4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Liberaries"
      ],
      "metadata": {
        "id": "JmZ5mHhaXFjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git python-pptx google-generativeai\n",
        "!pip install -q chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waVaqFXaXT__",
        "outputId": "5a6db0e8-ca79-4f65-9e7a-03be0a008b19"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import uuid\n",
        "import logging\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from google import genai\n",
        "\n",
        "import whisper\n",
        "from pptx import Presentation\n",
        "from pptx.util import Pt, Inches\n",
        "from pptx.dml.color import RGBColor\n",
        "from pptx.enum.shapes import MSO_SHAPE\n",
        "from google.genai import types, Client\n",
        "from google.api_core import retry\n",
        "import chromadb\n",
        "from chromadb.utils.embedding_functions import EmbeddingFunction\n",
        "import enum\n",
        "from IPython.display import Markdown, display\n",
        "from pptx.util import Inches\n",
        "from PIL import Image, ImageEnhance"
      ],
      "metadata": {
        "id": "LG3_-TfuXVB_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
        "\n",
        "genai.models.Models.generate_content = retry.Retry(\n",
        "    predicate=is_retriable)(genai.models.Models.generate_content)"
      ],
      "metadata": {
        "id": "fnyxzxQIXZuU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to create a PPT File"
      ],
      "metadata": {
        "id": "yM0oSkPrYF_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Constants\n",
        "MODEL_NAME = \"gemini-2.0-flash\"\n",
        "EMBEDDING_MODEL = \"models/text-embedding-004\"\n",
        "\n",
        "CHROMA_STORAGE_PATH = Path(\"./chroma_storage\")\n",
        "COLLECTION_NAME = \"meeting_summary_collection\"\n",
        "\n",
        "PPTX_FILENAME = \"Meeting Summary.pptx\"\n",
        "MEETING_THEMES = {\n",
        "    \"team_sync\": {\"title\": \"Team Sync\",\"color\": \"#8E44AD\",  \"bg_image\": Path(\"/content/meeting-2.jpg\")},\n",
        "    \"project_kickoff\": {\"title\": \"Project Kickoff\", \"color\": \"#8E44AD\",  \"bg_image\": Path(\"/content/meeting-1.jpg\")},\n",
        "    \"retrospective\": {\"title\": \"Sprint Retrospective\", \"color\": \"#8E44AD\",  \"bg_image\": Path(\"//content/meeting-4.jpg\")},\n",
        "    \"client_review\": {\"title\": \"Client Review\", \"color\": \"#8E44AD\",  \"bg_image\": Path(\"/content/meeting-3.jpg\")},\n",
        "    \"default\": {\"title\": \"Meeting Summary\", \"color\": \"#8E44AD\",  \"bg_image\": Path(\"/content/meeting-5.jpg\")},\n",
        "}\n",
        "\n",
        "MAX_OUTPUT_TOKENS = 9000\n",
        "TEMPERATURE = 0.4\n",
        "TOP_P = 0.9\n",
        "TOP_K = 40\n",
        "EMBEDDING_TASK = \"retrieval_document\""
      ],
      "metadata": {
        "id": "EBP5ReJ7Xde8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "# Suppress httpx and google_genai.models INFO logs by default\n",
        "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"google_genai.models\").setLevel(logging.WARNING)\n",
        "\n",
        "# Configure root logger\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
        ")"
      ],
      "metadata": {
        "id": "hw1PqcHuYQ2r"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load your .env\n",
        "load_dotenv()\n",
        "api_key = os.getenv(\"AIzaSyB5xPZxC4ygsj70enxaGfQ6AIERTBtFuEE\")\n",
        "GOOGLE_API_KEY=\"AIzaSyB5xPZxC4ygsj70enxaGfQ6AIERTBtFuEE\"\n",
        "# Configure the GenAI client\n",
        "genai.configure(api_key=\"AIzaSyB5xPZxC4ygsj70enxaGfQ6AIERTBtFuEE\")\n",
        "\n",
        "# Correct model name\n",
        "model = genai.GenerativeModel(model_name=\"models/gemini-pro\")\n"
      ],
      "metadata": {
        "id": "ZHI43w7UYa9H"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Audio File"
      ],
      "metadata": {
        "id": "2IuXuGueYjbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "src_path = Path('/content/meeting-clip2.wav')\n",
        "if not src_path.exists():\n",
        "    raise FileNotFoundError(\"Audio file not found\")\n",
        "\n",
        "print(\"Using audio file:\", src_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck5v37VpYmpV",
        "outputId": "83333605-75a9-4c20-9d6f-87d588c0f6d3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using audio file: /content/meeting-clip2.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save audio file\n",
        "def save_file(content):\n",
        "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')\n",
        "    temp_file.write(content)\n",
        "    temp_file.close()\n",
        "    return Path(temp_file.name)"
      ],
      "metadata": {
        "id": "g98tvW6YYqM0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Audio Transcription (Whisper)\n",
        "This component leverages the Whisper model to convert spoken meeting audio into raw text.\n",
        "It loads a pre-trained model and provides transcription capabilities, enabling accurate speech-to-text conversion for meeting recordings."
      ],
      "metadata": {
        "id": "ZBsULJ7DY5ra"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6OhGlTTUZGuC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioTranscriber:\n",
        "    \"\"\"\n",
        "    Transcribe speech to text using Whisper.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name = \"base\"):\n",
        "        try:\n",
        "            self.model = whisper.load_model(model_name)\n",
        "            logger.info(f\"Loaded Whisper model '{model_name}'\")\n",
        "        except Exception:\n",
        "            logger.exception(\"Failed to load Whisper model.\")\n",
        "            raise\n",
        "\n",
        "    def transcribe(self, audio_path):\n",
        "        \"\"\"\n",
        "        Transcribe the audio file and return the transcript.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            result = self.model.transcribe(str(audio_path))\n",
        "            logger.info(\"Transcription successful.\")\n",
        "            return result.get(\"text\", \"\")\n",
        "        except Exception:\n",
        "            logger.exception(f\"Transcription failed for {audio_path}\")\n",
        "            raise"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T05:52:41.707163Z",
          "iopub.execute_input": "2025-04-21T05:52:41.707446Z",
          "iopub.status.idle": "2025-04-21T05:52:41.725678Z",
          "shell.execute_reply.started": "2025-04-21T05:52:41.707416Z",
          "shell.execute_reply": "2025-04-21T05:52:41.724756Z"
        },
        "id": "Vl-wnjBaGRB7"
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Meeting Summarization (Gemini)\n",
        "This module uses Google's Gemini API to generate concise summaries from meeting transcripts.\n",
        "It sends a carefully crafted prompt and expects a structured JSON response, which is parsed and used for downstream tasks such as slide generation and Q&A."
      ],
      "metadata": {
        "id": "6J8NMbYQZVju"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ohx19Y1dZNSz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MeetingSummarizer:\n",
        "    \"\"\"\n",
        "    Summarizes meeting transcripts via Google GenAI.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, client):\n",
        "        self.client = client\n",
        "\n",
        "    def summarize(self, transcript, prompt):\n",
        "        \"\"\"\n",
        "        Generates a structured summary (sections with titles, summary, bullets).\n",
        "        \"\"\"\n",
        "\n",
        "        config = types.GenerateContentConfig(\n",
        "            max_output_tokens=MAX_OUTPUT_TOKENS,\n",
        "            temperature=TEMPERATURE,\n",
        "            top_p=TOP_P,\n",
        "            top_k=TOP_K,\n",
        "        )\n",
        "        try:\n",
        "            resp = self.client.models.generate_content(\n",
        "                model=MODEL_NAME, config=config, contents=[prompt, transcript]\n",
        "            )\n",
        "            summary_text = resp.text\n",
        "            json_str = summary_text.split(\"```json\")[1].split(\"```\")[0]\n",
        "            summary_slides = json.loads(json_str)\n",
        "            logger.info(\"Parsed summary to JSON.\")\n",
        "            return summary_slides, summary_text\n",
        "        except Exception:\n",
        "            logger.exception(\"Summarization error.\")\n",
        "            raise"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T05:52:41.726604Z",
          "iopub.execute_input": "2025-04-21T05:52:41.726903Z",
          "iopub.status.idle": "2025-04-21T05:52:41.742024Z",
          "shell.execute_reply.started": "2025-04-21T05:52:41.726884Z",
          "shell.execute_reply": "2025-04-21T05:52:41.741089Z"
        },
        "id": "q8j7mWZlGRB8"
      },
      "outputs": [],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation with Gemini (Rubric-Based)\n",
        "This component leverages Google Gemini to evaluate the quality of generated meeting summaries using a rubric-based prompt.\n",
        "The model assesses the summary across key dimensions:\n",
        "\n",
        "üß± Slide Structure\n",
        "\n",
        "üìå Groundedness\n",
        "\n",
        "‚úÇÔ∏è Conciseness\n",
        "\n",
        "üó£Ô∏è Fluency\n",
        "\n",
        "By mimicking human feedback, this automated review loop ensures consistency and quality in the generated content."
      ],
      "metadata": {
        "id": "YLFtnc8hZkW4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEo8YRU0Zm-P"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SummaryRating(enum.Enum):\n",
        "    VERY_GOOD = '5'\n",
        "    GOOD = '4'\n",
        "    OK = '3'\n",
        "    BAD = '2'\n",
        "    VERY_BAD = '1'\n",
        "\n",
        "class SummaryEvaluator:\n",
        "    \"\"\"\n",
        "    Evaluates Summary generated from transcript via Google GenAI.\n",
        "    \"\"\"\n",
        "    def __init__(self, client):\n",
        "        self.client = client\n",
        "\n",
        "    def eval(self, summary, transcript, summary_prompt):\n",
        "        \"\"\"\n",
        "        Evaluate the summary of the transcript and provide a rating on a scale 1 to 5, 1 being \"Very Poor\" and 5 being \"Excellent\"\n",
        "        \"\"\"\n",
        "        prompt = (f\"\"\"\n",
        "            # Instruction\n",
        "            You are an expert evaluator for slide presentations. Your task is to evaluate the quality of a meeting summary generated for a transcript by an AI model, which is intended to be turned into a PowerPoint slide deck.\n",
        "\n",
        "            We will provide you with the original prompt and transcript given to the model and the AI-generated structured summary. Your evaluation should focus on whether this summary is effective for slide-based presentation.\n",
        "\n",
        "            # Evaluation\n",
        "            ## Metric Definition\n",
        "            You will assess the meeting summary‚Äôs quality with regard to slide-readiness. A good slide summary should:\n",
        "            - Break the content into clear sections\n",
        "            - Contain accurate and concise summaries\n",
        "            - Use bullet points that can be used directly in presentation slides\n",
        "            - Avoid introducing information that wasn't in the source\n",
        "\n",
        "            ## Criteria\n",
        "            1. **Structure for Slides**: The summary is clearly broken down into presentation-friendly sections with meaningful titles.\n",
        "            2. **Groundedness**: The summary uses only content grounded in the original meeting transcript and does not hallucinate.\n",
        "            3. **Conciseness and Slide-Readiness**: The bullets are clear, well-chunked, and ready to be used on slides (not full paragraphs).\n",
        "            4. **Fluency and Readability**: The summaries and bullets are easy to understand and grammatically correct.\n",
        "\n",
        "            ## Rating Rubric\n",
        "            5 (Excellent): Summary is well-structured, fully grounded, concise, and presentation-ready with fluent writing.\n",
        "            4 (Good): Summary is mostly well-structured and grounded; bullets are usable with minor edits.\n",
        "            3 (Fair): Summary is okay but needs editing to be usable in slides (e.g., too verbose, not well-structured).\n",
        "            2 (Poor): Summary is grounded but hard to use in a slide deck without major revisions.\n",
        "            1 (Very Poor): Summary is ungrounded, off-topic, or incoherent.\n",
        "\n",
        "            ## Evaluation Steps\n",
        "            STEP 1: Assess the summary for presentation-readiness using the 4 criteria.\n",
        "            STEP 2: Score the summary using the rubric.\n",
        "\n",
        "            # User Inputs and AI-generated Response\n",
        "            ## Prompt\n",
        "            {summary_prompt}\n",
        "            ## transcript\n",
        "            {transcript}\n",
        "\n",
        "            ## AI-generated Summary (JSON format intended for slide generation)\n",
        "            ```\n",
        "            {summary}\n",
        "            ```\n",
        "                \"\"\"\n",
        "        )\n",
        "        try:\n",
        "            resp = self.client.chats.create(\n",
        "                model=MODEL_NAME).send_message(prompt)\n",
        "            verbose_eval = resp.text\n",
        "            logger.info(\"Evaluated the summary generated.\")\n",
        "            return verbose_eval\n",
        "        except Exception:\n",
        "            logger.exception(\"Evaluation error.\")\n",
        "            raise\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T05:52:41.743038Z",
          "iopub.execute_input": "2025-04-21T05:52:41.743325Z",
          "iopub.status.idle": "2025-04-21T05:52:41.767207Z",
          "shell.execute_reply.started": "2025-04-21T05:52:41.743303Z",
          "shell.execute_reply": "2025-04-21T05:52:41.766166Z"
        },
        "id": "L-64O1ZXGRB-"
      },
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Slide Generation (python-pptx)\n",
        "This module utilizes the python-pptx library to automatically transform the structured JSON summary into a polished PowerPoint presentation.\n",
        "\n",
        "Each slide is dynamically generated with:\n",
        "\n",
        "üè∑Ô∏è Section Titles\n",
        "\n",
        "üìù Concise Summaries\n",
        "\n",
        "üîò Bullet Points, styled for clarity and readability\n",
        "\n",
        "The goal is to eliminate the manual effort of turning meeting notes into presentation-ready slides ‚Äî saving time and ensuring consistency."
      ],
      "metadata": {
        "id": "WTWXBWU4Z0Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOQAVSfkZ2W0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PPTGenerator:\n",
        "    \"\"\"\n",
        "    Create a PowerPoint from structured summary.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, themes):\n",
        "        self.themes = themes\n",
        "\n",
        "    @staticmethod\n",
        "    def hex_to_rgb(h):\n",
        "        h = h.lstrip(\"#\")\n",
        "        return tuple(int(h[i : i + 2], 16) for i in (0, 2, 4))\n",
        "\n",
        "    @staticmethod\n",
        "    def is_dark(rgb):\n",
        "        r, g, b = rgb\n",
        "        return (0.299 * r + 0.587 * g + 0.114 * b) < 150\n",
        "\n",
        "    @staticmethod\n",
        "    def add_bg(slide, rgb, image_path):\n",
        "        \"\"\"\n",
        "        Adds a background image or fallback color to the slide.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if image_path:\n",
        "                # Resize image first\n",
        "                with Image.open(image_path) as img:\n",
        "                    img = img.resize((960, 720))  # PowerPoint slide size\n",
        "                    temp_path = \"/tmp/resized_bg.jpg\"\n",
        "                    img.save(temp_path)\n",
        "\n",
        "                # Apply opacity to resized image\n",
        "                faded_path = \"/tmp/faded_bg.png\"\n",
        "                PPTGenerator.apply_opacity(temp_path, faded_path, opacity=0.3)\n",
        "\n",
        "                # Add faded image to slide\n",
        "                img_shape = slide.shapes.add_picture(faded_path, 0, 0, width=Inches(10), height=Inches(7.5))\n",
        "\n",
        "                # Send to back of z-order\n",
        "                spTree = slide.shapes._spTree\n",
        "                spTree.remove(img_shape._element)\n",
        "                spTree.insert(2, img_shape._element)\n",
        "                return\n",
        "        except Exception:\n",
        "            logger.exception(\"Background image failed. Falling back to color.\")\n",
        "\n",
        "        # Fallback to solid color background\n",
        "        if rgb:\n",
        "            shape = slide.shapes.add_shape(\n",
        "                MSO_SHAPE.RECTANGLE, Inches(0), Inches(0), Inches(10), Inches(7.5)\n",
        "            )\n",
        "            shape.fill.solid()\n",
        "            shape.fill.fore_color.rgb = RGBColor(*rgb)\n",
        "            shape.line.fill.background()\n",
        "            slide.shapes._spTree.insert(2, slide.shapes._spTree[-1])\n",
        "    @staticmethod\n",
        "    def apply_opacity(image_path, output_path, opacity = 0.3):\n",
        "        \"\"\"\n",
        "        Saves a faded version of the image to use as background.\n",
        "        \"\"\"\n",
        "        img = Image.open(image_path).convert(\"RGBA\")\n",
        "        alpha = img.split()[3]\n",
        "        alpha = ImageEnhance.Brightness(alpha).enhance(opacity)\n",
        "        img.putalpha(alpha)\n",
        "        img.save(output_path)\n",
        "\n",
        "    def generate(self, sections, filename, mtype = \"default\"):\n",
        "        \"\"\"\n",
        "        Build and save the .pptx file.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            theme = MEETING_THEMES.get(mtype, MEETING_THEMES[\"default\"])\n",
        "            rgb = self.hex_to_rgb(theme[\"color\"])\n",
        "            bg_image = theme.get(\"bg_image\")\n",
        "            font_rgb = (0, 0, 0)\n",
        "            use_light_text = self.is_dark(rgb)\n",
        "            prs = Presentation()\n",
        "\n",
        "            # Title Slide\n",
        "            slide = prs.slides.add_slide(prs.slide_layouts[0])\n",
        "            self.add_bg(slide, rgb=rgb, image_path=bg_image)\n",
        "            slide.shapes.title.text = theme[\"title\"]\n",
        "            slide.shapes.title.text_frame.paragraphs[0].font.color.rgb = RGBColor(\n",
        "                *font_rgb\n",
        "            )\n",
        "            body = slide.placeholders[1]\n",
        "            body.text = filename.stem\n",
        "            body.text_frame.paragraphs[0].font.color.rgb = RGBColor(*font_rgb)\n",
        "\n",
        "            # TOC\n",
        "            toc = prs.slides.add_slide(prs.slide_layouts[1])\n",
        "            self.add_bg(toc, rgb=rgb, image_path=bg_image)\n",
        "            toc.shapes.title.text = \"Table of Contents\"\n",
        "            toc.shapes.title.text_frame.paragraphs[0].font.color.rgb = RGBColor(\n",
        "                *font_rgb\n",
        "            )\n",
        "            toc_body = toc.placeholders[1]\n",
        "            toc_body.text = \"\\n\".join(s[\"section_title\"] for s in sections)\n",
        "            for p in toc_body.text_frame.paragraphs:\n",
        "                p.font.color.rgb = RGBColor(*font_rgb)\n",
        "\n",
        "            # Content Slides\n",
        "            for sec in sections:\n",
        "                sld = prs.slides.add_slide(prs.slide_layouts[1])\n",
        "                self.add_bg(sld, rgb=rgb, image_path=bg_image)\n",
        "                sld.shapes.title.text = sec[\"section_title\"]\n",
        "                sld.shapes.title.text_frame.paragraphs[0].font.color.rgb = RGBColor(\n",
        "                    *font_rgb\n",
        "                )\n",
        "                box = sld.placeholders[1]\n",
        "                tf = box.text_frame\n",
        "                tf.clear()\n",
        "                summary_text = sec.get(\"summary\", \"\")\n",
        "                summary_pt = tf.add_paragraph()\n",
        "                summary_pt.text = f\"Summary: {summary_text}\"\n",
        "                summary_pt.font.size = Pt(18)\n",
        "                summary_pt.font.color.rgb = RGBColor(*font_rgb)\n",
        "                summary_pt.font.bold = True\n",
        "                for bullet in sec.get(\"bullets\", []):\n",
        "                    pb = tf.add_paragraph()\n",
        "                    pb.text = bullet\n",
        "                    pb.level = 1\n",
        "                    pb.font.size = Pt(20)\n",
        "                    pb.font.color.rgb = RGBColor(*font_rgb)\n",
        "\n",
        "\n",
        "            prs.save(str(filename))\n",
        "            logger.info(f\"PPT saved: {filename}\")\n",
        "        except Exception:\n",
        "            logger.exception(\"Failed PPT generation.\")\n",
        "            raise"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T05:52:41.768126Z",
          "iopub.execute_input": "2025-04-21T05:52:41.768375Z",
          "iopub.status.idle": "2025-04-21T05:52:41.79154Z",
          "shell.execute_reply.started": "2025-04-21T05:52:41.768354Z",
          "shell.execute_reply": "2025-04-21T05:52:41.790435Z"
        },
        "id": "7nBzVJ3tGRCA"
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding and Retrieval (RAG)\n",
        "This module implements Retrieval-Augmented Generation (RAG) by embedding previous meeting transcripts and storing them in a vector database (ChromaDB).\n",
        "\n",
        "When processing new meetings, relevant past meetings are retrieved based on semantic similarity, providing valuable context or identifying recurring themes.\n",
        "\n",
        "This approach enhances the agent's memory and ability to recognize long-term patterns, improving both the accuracy and relevance of generated insights."
      ],
      "metadata": {
        "id": "SUhSZTcyaSX1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Jo3swyFadLM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGEngine:\n",
        "    \"\"\"\n",
        "    Retrieval-Augmented Generation using ChromaDB.\n",
        "    \"\"\"\n",
        "    def __init__(self, client, storage_path, collection_name):\n",
        "        self.client = client\n",
        "        self.storage_path = storage_path\n",
        "        self.collection_name = collection_name\n",
        "\n",
        "    class _EmbeddingFn(EmbeddingFunction):\n",
        "        def __init__(self, client, model):\n",
        "            self.client = client\n",
        "            self.model = model\n",
        "\n",
        "        def __call__(self, texts):\n",
        "            try:\n",
        "                res = self.client.models.embed_content(\n",
        "                    model=self.model,\n",
        "                    contents=texts,\n",
        "                    config=types.EmbedContentConfig(\n",
        "                    task_type=EMBEDDING_TASK,\n",
        "                    ),\n",
        "                )\n",
        "                raw = getattr(res, 'embeddings', None) or res.get('embeddings') or res.get('embedding')\n",
        "                if not raw:\n",
        "                    raise ValueError(\"No embeddings returned from GenAI.\")\n",
        "                processed = [item.values if hasattr(item, 'values') else item for item in raw]\n",
        "                return processed\n",
        "            except Exception:\n",
        "                logger.exception(\"Embedding failed.\")\n",
        "                return []\n",
        "\n",
        "    def init_db(self) :\n",
        "        \"\"\"\n",
        "        Initialize or get a ChromaDB collection.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            client = chromadb.PersistentClient(path=str(self.storage_path))\n",
        "            existing = [col.name for col in client.list_collections()]\n",
        "            if self.collection_name in existing:\n",
        "                logger.info(\"Using existing ChromaDB collection.\")\n",
        "                return client.get_collection(name=self.collection_name)\n",
        "            logger.info(f\"Creating new ChromaDB collection: {self.collection_name}\")\n",
        "            return client.create_collection(\n",
        "                name=self.collection_name,\n",
        "                embedding_function=self._EmbeddingFn(self.client, EMBEDDING_MODEL)\n",
        "            )\n",
        "        except Exception:\n",
        "            logger.exception(\"Failed to initialize ChromaDB collection.\")\n",
        "            raise\n",
        "\n",
        "    def add_document(self, db, text):\n",
        "        \"\"\"\n",
        "        Add a document to ChromaDB.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if text:\n",
        "                db.add(documents=[text], ids=[str(uuid.uuid4())])\n",
        "                logger.info(\"Document added to ChromaDB.\")\n",
        "        except Exception:\n",
        "            logger.exception(\"Failed to add document to ChromaDB.\")\n",
        "\n",
        "    def query(self, db, query, k = 2):\n",
        "        \"\"\"\n",
        "        Query ChromaDB for top-k relevant documents.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            result = db.query(query_texts=[query], n_results=k)\n",
        "            return result.get('documents', [])\n",
        "        except Exception:\n",
        "            logger.exception(\"Failed to query ChromaDB.\")\n",
        "            return []\n",
        "\n",
        "    def answer(self, db, query, k = 2):\n",
        "        \"\"\"\n",
        "        Answer a question using retrieved passages from ChromaDB.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            passages = self.query(db, query, k)\n",
        "            prompt = (\n",
        "                f\"\"\"You are a helpful and informative bot that answers questions using only the\n",
        "                provided reference passage below.\n",
        "\n",
        "                Instructions:\n",
        "                - Provide a complete, well-explained answer based solely on the passage.\n",
        "                - If the answer is not available, respond with: \"I'm not sure.\"\n",
        "                - You are responding to a technical audience, so explain clearly but concisely.\n",
        "                - Break down complex concepts into understandable parts.\n",
        "                - Ignore irrelevant information.\n",
        "\n",
        "                Passage:\n",
        "                {passages}\n",
        "\n",
        "                Question:\n",
        "                {query}\n",
        "\n",
        "                Answer:RAG Q&A\"\"\"\n",
        "            )\n",
        "            resp = self.client.models.generate_content(\n",
        "                model=MODEL_NAME,\n",
        "                contents=[prompt]\n",
        "            )\n",
        "            return resp.text.strip()\n",
        "        except Exception:\n",
        "            logger.exception(\"Failed to generate answer.\")\n",
        "            return \"I'm not sure.\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T05:52:41.792657Z",
          "iopub.execute_input": "2025-04-21T05:52:41.793306Z",
          "iopub.status.idle": "2025-04-21T05:52:41.813303Z",
          "shell.execute_reply.started": "2025-04-21T05:52:41.793271Z",
          "shell.execute_reply": "2025-04-21T05:52:41.81234Z"
        },
        "id": "dXsQnfYyGRCB"
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "source": [
        "#End-to-End Workflow: Transcribe ‚Üí Summarize ‚Üí Evaluate ‚Üí Generate Slides ‚Üí Retrieve ‚Üí Q&A\n",
        "This function orchestrates the complete MinuteMaker pipeline, showcasing a fully integrated GenAI workflow:\n",
        "\n",
        "**Transcribe**\n",
        "Converts raw meeting audio into text using OpenAI Whisper.\n",
        "\n",
        "**Summarize**\n",
        "Sends the transcript to Google Gemini with structured prompts to generate a JSON-based summary.\n",
        "\n",
        "**Evaluate**\n",
        "Uses a rubric-based GenAI evaluator to score the summary for structure, clarity, and fluency.\n",
        "\n",
        "**Detect Theme**\n",
        "Classifies the meeting type (e.g., retrospective, planning, kickoff) for context-aware processing.\n",
        "\n",
        "**Generate Slides**\n",
        "Transforms the structured summary into a PowerPoint presentation using python-pptx.\n",
        "\n",
        "**RAG Q&A**\n",
        "Embeds the transcript in ChromaDB and performs retrieval-augmented question answering to support context-rich chat or queries.\n",
        "\n",
        "This design demonstrates a powerful GenAI application pipeline that combines:\n",
        "\n",
        "üîÅ Multimodal processing\n",
        "\n",
        "üßæ Structured prompting\n",
        "\n",
        "‚úÖ Automated evaluation\n",
        "\n",
        "üß† Knowledge retrieval\n",
        "\n",
        "üéØ Content generation"
      ],
      "metadata": {
        "id": "1D1Yz4Oha_Mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(audio_bytes):\n",
        "    \"\"\"\n",
        "    Workflow: transcribe -> summarize and RAG Q&A -> detect type -> ppt\n",
        "    \"\"\"\n",
        "    try:\n",
        "        key = GOOGLE_API_KEY\n",
        "        gen_client = Client(api_key=key)\n",
        "\n",
        "        #### Transcription ####\n",
        "        transcriber = AudioTranscriber()\n",
        "        path = save_file(audio_bytes)\n",
        "        transcript = transcriber.transcribe(path)\n",
        "\n",
        "        #### Summarization ####\n",
        "        summary_prompt = (\"\"\"\n",
        "            You are a meeting assistant. Carefully analyze the meeting transcript and:\n",
        "                1. Segment it into distinct topics (whenever the conversation focus shifts).\n",
        "                2. For each topic:\n",
        "                  - Assign a meaningful short section_title (max 1 line).\n",
        "                  - Write a concise 1-sentence summary.\n",
        "                  - Extract 2-3 bullet points (each bullet under 50 words).\n",
        "\n",
        "            Think step by step. Identify topic shifts chronologically.\n",
        "            Return the result strictly in the JSON format. All keys must be in double quotes:\n",
        "                ```\n",
        "                  {\n",
        "                    \"section_title\": \"Team Updates\",\n",
        "                    \"summary\": \"...\",\n",
        "                    \"bullets\": [\"...\", \"...\", \"...\"]\n",
        "                  },\n",
        "                  ...\n",
        "                ```\n",
        "                \"\"\"\n",
        "        )\n",
        "        summarizer = MeetingSummarizer(gen_client)\n",
        "        summary, summary_text = summarizer.summarize(transcript, summary_prompt)\n",
        "        display(Markdown(\"### **1. Structured output of the Summary**\"))\n",
        "        display(Markdown(summary_text))\n",
        "\n",
        "        #### Summary Evaluation ####\n",
        "        evaluate = SummaryEvaluator(gen_client)\n",
        "        evaluation = evaluate.eval(summary, transcript, summary_prompt)\n",
        "        display(Markdown(f\"### 2. Rubric-Based Evaluation\\n{evaluation}\"))\n",
        "\n",
        "        #### Theme Detection ####\n",
        "        theme_prompt = (\"\"\"\n",
        "        You're a Meeting assistant. Given the context, understand it and choose the meeting type accordingly from the list:\n",
        "        [\"team_sync\", \"project_kickoff\", \"client_review\", \"retrospective\"].\n",
        "\n",
        "        Reply with just the meeting type.\n",
        "        \"\"\"\n",
        "        )\n",
        "        theme_resp = gen_client.models.generate_content(\n",
        "            model=MODEL_NAME, contents=[theme_prompt, transcript]\n",
        "        )\n",
        "        mtype = theme_resp.text.strip().lower()\n",
        "        display(Markdown(\"### **3. Meeting Type**\"))\n",
        "        display(Markdown(mtype))\n",
        "\n",
        "        #### PPT generation ####\n",
        "        ppt = PPTGenerator(MEETING_THEMES)\n",
        "        ppt.generate(summary, Path(PPTX_FILENAME), mtype)\n",
        "\n",
        "        #### RAG Q&A using Chroma ####\n",
        "        rag = RAGEngine(gen_client, CHROMA_STORAGE_PATH, COLLECTION_NAME)\n",
        "        db = rag.init_db()\n",
        "        rag.add_document(db, transcript)\n",
        "\n",
        "\n",
        "        # Example QA\n",
        "        questions = [\n",
        "            \"What's the main priority for getting people to the underused room?\",\n",
        "            \"What audience groups are excluded?\",\n",
        "            \"What's the plan for distributing audio recordings or 'CDs' post-session?\",\n",
        "        ]\n",
        "\n",
        "        display(Markdown(\"### **4. RAG Q&A**\"))\n",
        "        for question in questions:\n",
        "            display(Markdown(\"Q:\" + question))\n",
        "            ans = rag.answer(db, question, k=2)\n",
        "            display(Markdown(\"Ans:\"+ans))\n",
        "\n",
        "    except Exception:\n",
        "        logger.exception(\"Main workflow error.\")\n",
        "        raise\n",
        "    display(Markdown(\"### **Done**\"))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    audio_bytes = src_path.read_bytes()\n",
        "    main(audio_bytes)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T05:52:41.815795Z",
          "iopub.execute_input": "2025-04-21T05:52:41.816067Z",
          "iopub.status.idle": "2025-04-21T05:53:49.21237Z",
          "shell.execute_reply.started": "2025-04-21T05:52:41.816047Z",
          "shell.execute_reply": "2025-04-21T05:53:49.211435Z"
        },
        "id": "Kl5PU4hpGRCE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "594523ff-bd4c-47d7-8345-5faf7c05e2af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### **1. Structured output of the Summary**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n[\n  {\n    \"section_title\": \"Initial Proposal Discussion\",\n    \"summary\": \"The team acknowledges Paul's proposal but expresses initial concerns about inflexible core hours and suggests further individual review before a deeper discussion.\",\n    \"bullets\": [\n      \"Paul's proposal is acknowledged as a starting point.\",\n      \"Concerns are raised about the rigidity of core hours.\",\n      \"Team members need time to review the proposal individually.\"\n    ]\n  }\n]\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### 2. Rubric-Based Evaluation\n## Evaluation\n\n**STEP 1: Assess the summary for presentation-readiness using the 4 criteria.**\n\n*   **Structure for Slides:** The summary is structured with a section title, a summary sentence, and bullet points, which aligns with the prompt instructions and is suitable for slide creation.\n*   **Groundedness:** The summary and bullet points accurately reflect the content of the original transcript. No hallucination is present.\n*   **Conciseness and Slide-Readiness:** The summary sentence is concise and the bullet points are short and to the point, making them ready to be placed directly onto slides.\n*   **Fluency and Readability:** The language used is clear, grammatically correct, and easy to understand.\n\n**STEP 2: Score the summary using the rubric.**\n\n*   **Score:** 5 (Excellent)\n\nThe summary is well-structured, fully grounded, concise, presentation-ready, and fluent. It perfectly follows the instructions and delivers a high-quality slide-ready summary.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### **3. Meeting Type**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "team_sync"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### **4. RAG Q&A**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Q:What's the main priority for getting people to the underused room?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Ans:I'm not sure."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Q:What audience groups are excluded?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Ans:I'm not sure."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Q:What's the plan for distributing audio recordings or 'CDs' post-session?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Ans:I'm not sure."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### **Done**"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32
    }
  ]
}